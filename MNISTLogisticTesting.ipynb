{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "tensor([8])\n",
      "0.00042483300785534084\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "dataset = FashionMNIST(root = 'data/', download = True, transform = ToTensor())\n",
    "\n",
    "amountHiddenLayers = 1\n",
    "activationFuncs = [F.relu, F.leaky_relu, F.tanh, F.sigmoid]\n",
    "currActivationFunc = F.relu\n",
    "\n",
    "def getDefaultDevice():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device('cpu')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = getDefaultDevice()\n",
    "\n",
    "loader = DataLoader(dataset)\n",
    "\n",
    "\n",
    "class TempModel(nn.Module):\n",
    "        #create hidden layer and output layer\n",
    "        def __init__(self, inSize, hiddenSize1, hiddenSize2, hiddenSize3, hiddenSize4, hiddenSize5, outSize):\n",
    "            super().__init__()\n",
    "\n",
    "            if (amountHiddenLayers == 1):\n",
    "                    self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                    self.linear2 = nn.Linear(hiddenSize1, outSize).to(device)\n",
    "            elif (amountHiddenLayers == 2):\n",
    "                self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                self.linear2 = nn.Linear(hiddenSize1, hiddenSize2).to(device)\n",
    "                self.linear3 = nn.Linear(hiddenSize2, outSize).to(device)\n",
    "            elif (amountHiddenLayers == 3):\n",
    "                self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                self.linear2 = nn.Linear(hiddenSize1, hiddenSize2).to(device)\n",
    "                self.linear3 = nn.Linear(hiddenSize2, hiddenSize3).to(device)\n",
    "                self.linear4 = nn.Linear(hiddenSize3, outSize).to(device)\n",
    "            elif (amountHiddenLayers == 4):\n",
    "                self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                self.linear2 = nn.Linear(hiddenSize1, hiddenSize2).to(device)\n",
    "                self.linear3 = nn.Linear(hiddenSize2, hiddenSize3).to(device)\n",
    "                self.linear4 = nn.Linear(hiddenSize3, hiddenSize4).to(device)\n",
    "                self.linear5 = nn.Linear(hiddenSize4, outSize).to(device)\n",
    "            else:\n",
    "                self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                self.linear2 = nn.Linear(hiddenSize1, outSize).to(device)\n",
    "        \n",
    "\n",
    "        def forward(self, xb): #xb is batch of data\n",
    "            if (amountHiddenLayers == 1):\n",
    "                        \n",
    "                #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "         \n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear3(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear4(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "            \n",
    "            \n",
    "            elif (amountHiddenLayers == 2):\n",
    "                        \n",
    "                #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "              \n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "              \n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear3(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear4(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "            \n",
    "            \n",
    "            elif (amountHiddenLayers == 3):\n",
    "                        #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "        \n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "            \n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear3(out)\n",
    "               \n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear4(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "            \n",
    "                            \n",
    "            elif (amountHiddenLayers == 4):\n",
    "                        #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "              \n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear3(out)\n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear4(out)\n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "            \n",
    "            else:\n",
    "                #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear3(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear4(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "\n",
    "if (amountHiddenLayers == 1):\n",
    "    model = TempModel(784, hiddenSize1 = 32, hiddenSize2=128, hiddenSize3=32, hiddenSize4=16, hiddenSize5=0, outSize = 10)\n",
    "elif (amountHiddenLayers==2):\n",
    "\n",
    "    model = TempModel(784, hiddenSize1 = 64, hiddenSize2=32, hiddenSize3=32, hiddenSize4=16, hiddenSize5=0, outSize = 10)\n",
    "elif(amountHiddenLayers==3):\n",
    "    model = TempModel(784, hiddenSize1 = 64, hiddenSize2=128, hiddenSize3=32, hiddenSize4=16, hiddenSize5=0, outSize = 10)\n",
    "elif(amountHiddenLayers==4):\n",
    "    model = TempModel(784, hiddenSize1 = 64, hiddenSize2=256, hiddenSize3=64, hiddenSize4=16, hiddenSize5=0, outSize = 10)\n",
    "torch.load('model' + str(amountHiddenLayers)+'.pt')\n",
    "model.eval()\n",
    "\n",
    "def predictImage(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    print(preds)\n",
    "    return preds[0].item\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03b0a5ea72e569892ff75cdce4f0a43aa28d5543ecfacea9505a52dbab1ee89a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
