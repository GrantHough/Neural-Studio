{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "0\n",
      "tensor([0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting PyTorch Frontend ==> MIL Ops:  94%|█████████▍| 15/16 [00:00<00:00, 2281.08 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 10591.68 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 56/56 [00:00<00:00, 3407.58 passes/s]\n",
      "Running MIL backend_neuralnetwork pipeline: 100%|██████████| 8/8 [00:00<00:00, 29852.70 passes/s]\n",
      "Translating MIL ==> NeuralNetwork Ops: 100%|██████████| 21/21 [00:00<00:00, 185.91 ops/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib as plt\n",
    "import coremltools as ct\n",
    "\n",
    "dataset = MNIST(root = 'data/', download = True, transform = ToTensor())\n",
    "\n",
    "amountHiddenLayers = 4\n",
    "activationFuncs = [F.relu, F.leaky_relu, F.tanh, F.sigmoid]\n",
    "currActivationFunc = F.relu\n",
    "\n",
    "def getDefaultDevice():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device('cpu')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "device = getDefaultDevice()\n",
    "\n",
    "loader = DataLoader(dataset)\n",
    "\n",
    "\n",
    "class TempModel(nn.Module):\n",
    "        #create hidden layer and output layer\n",
    "        def __init__(self, inSize, hiddenSize1, hiddenSize2, hiddenSize3, hiddenSize4, hiddenSize5, outSize):\n",
    "            super().__init__()\n",
    "\n",
    "            if (amountHiddenLayers == 1):\n",
    "                    self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                    self.linear2 = nn.Linear(hiddenSize1, outSize).to(device)\n",
    "            elif (amountHiddenLayers == 2):\n",
    "                self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                self.linear2 = nn.Linear(hiddenSize1, hiddenSize2).to(device)\n",
    "                self.linear3 = nn.Linear(hiddenSize2, outSize).to(device)\n",
    "            elif (amountHiddenLayers == 3):\n",
    "                self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                self.linear2 = nn.Linear(hiddenSize1, hiddenSize2).to(device)\n",
    "                self.linear3 = nn.Linear(hiddenSize2, hiddenSize3).to(device)\n",
    "                self.linear4 = nn.Linear(hiddenSize3, outSize).to(device)\n",
    "            elif (amountHiddenLayers == 4):\n",
    "                self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                self.linear2 = nn.Linear(hiddenSize1, hiddenSize2).to(device)\n",
    "                self.linear3 = nn.Linear(hiddenSize2, hiddenSize3).to(device)\n",
    "                self.linear4 = nn.Linear(hiddenSize3, hiddenSize4).to(device)\n",
    "                self.linear5 = nn.Linear(hiddenSize4, outSize).to(device)\n",
    "            else:\n",
    "                self.linear1 = nn.Linear(inSize, hiddenSize1).to(device)\n",
    "                self.linear2 = nn.Linear(hiddenSize1, outSize).to(device)\n",
    "        \n",
    "\n",
    "        def forward(self, xb): #xb is batch of data\n",
    "            if (amountHiddenLayers == 1):\n",
    "                        \n",
    "                #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "         \n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear3(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear4(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "            \n",
    "            \n",
    "            elif (amountHiddenLayers == 2):\n",
    "                        \n",
    "                #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "              \n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "              \n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear3(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear4(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "            \n",
    "            \n",
    "            elif (amountHiddenLayers == 3):\n",
    "                        #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "        \n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "            \n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear3(out)\n",
    "               \n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear4(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "            \n",
    "                            \n",
    "            elif (amountHiddenLayers == 4):\n",
    "                        #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "              \n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear3(out)\n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear4(out)\n",
    "                out=currActivationFunc(out)\n",
    "                out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "            \n",
    "            else:\n",
    "                #flatten tensors\n",
    "                xb = xb.view(xb.size(0), -1) #xb.size(0) retains batch size input, -1 makes pytorch calculate so the model is general and can be used with images that dont have 784 pixels\n",
    "                #immediate outputs\n",
    "                out = self.linear1(xb)\n",
    "                #apply activation function\n",
    "\n",
    "                out=currActivationFunc(out)\n",
    "                #get predictions using output layer\n",
    "                out = self.linear2(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear3(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear4(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear5(out)\n",
    "                # out = F.relu(out)\n",
    "                # out = self.linear6(out)\n",
    "            \n",
    "                return out\n",
    "\n",
    "if (amountHiddenLayers == 1):\n",
    "    model = TempModel(784, hiddenSize1 = 32, hiddenSize2=128, hiddenSize3=32, hiddenSize4=16, hiddenSize5=0, outSize = 10)\n",
    "elif (amountHiddenLayers==2):\n",
    "\n",
    "    model = TempModel(784, hiddenSize1 = 64, hiddenSize2=32, hiddenSize3=0, hiddenSize4=0, hiddenSize5=0, outSize = 10)\n",
    "elif(amountHiddenLayers==3):\n",
    "    model = TempModel(784, hiddenSize1 = 64, hiddenSize2=128, hiddenSize3=32, hiddenSize4=0, hiddenSize5=0, outSize = 10)\n",
    "elif(amountHiddenLayers==4):\n",
    "    model = TempModel(784, hiddenSize1 = 128, hiddenSize2=512, hiddenSize3=128, hiddenSize4=32, hiddenSize5=0, outSize = 10)\n",
    "# torch.load('model' + str(amountHiddenLayers)+'.pt')\n",
    "model.load_state_dict(torch.load('models/goodmodel.pt'))\n",
    "\n",
    "def predictImage(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    print(preds)\n",
    "    return preds[0].item\n",
    "\n",
    "img, label = dataset[1]\n",
    "print(img.size())\n",
    "print(label)\n",
    "predictImage(img[0], model)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "example_input = torch.rand(1, 28, 28)\n",
    "\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "\n",
    "# model = ct.convert(\n",
    "#     traced_model,\n",
    "#     inputs=[ct.TensorType(shape=example_input.shape)]\n",
    "#  ) \n",
    "\n",
    "# model.save(\"goodmodel.mlmodel\")\n",
    "\n",
    "# predictImage(loader[0],)\n",
    "#good model has accuracy of 98.9%, bad model has accuracy of 11.2%\n",
    "#both had 25 epochs, bad had 1 hidden good had 4 hidden, good used leaky bad used reg relu, good had learning rate of 0.02, bad had learning rate of 0.5\n",
    "\n",
    "#Image dimension was like 000000000 the whole way I THINK, check\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "03b0a5ea72e569892ff75cdce4f0a43aa28d5543ecfacea9505a52dbab1ee89a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
